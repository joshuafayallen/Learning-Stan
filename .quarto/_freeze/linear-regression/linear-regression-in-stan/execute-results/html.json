{
  "hash": "125a4f83541650e0a5dd0a01d51f7033",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Linear Models in CmdStan and \"\nformat: html\n\n---\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(cmdstanr)\nlibrary(ggdist)\nlibrary(posterior)\nlibrary(tidybayes)\nlibrary(broom.mixed)\nlibrary(MetBrewer)\nlibrary(tidyverse)\n```\n:::\n\n\nYou goofed around and now have to learn how to use Stan and be able to do posterior stuff in Stan. They reccomend using `cmdstan` which is really just an interface to the command line tool. What is really great about cmdstan is that it is extremely fast and really flexible. I think you could say that one of the con is that you do have to program some of the posterior quantities of interest yourself. The good news is that for the most part you aren't pushing the frontiers of estimates. Stan is really just a lower level wrapper around some C++. To get the wrapper to work you have to follow a somewhat strict order \n\n\n```\nfunctions {\n  // ... function declarations and definitions ...\n}\ndata {\n  // ... declarations ...\n}\ntransformed data {\n   // ... declarations ... statements ...\n}\nparameters {\n   // ... declarations ...\n}\ntransformed parameters {\n   // ... declarations ... statements ...\n}\nmodel {\n   // ... declarations ... statements ...\n}\ngenerated quantities {\n   // ... declarations ... statements ...\n}\n\n```\n\nSome of these are optional it will just depend on the uses. \n\n\n## A simple model\n\nLets walk through the Howell example \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"Howell1\", package = \"rethinking\")\n\njust_adults <- Howell1 |>\n  filter(age > 18)\n\nmodel_code <- \"\ndata {\nint <lower=1> n;\nvector[n] height;\n}\nparameters {\nreal alpha;\nreal <lower = 0, upper = 50> sigma;\n}\nmodel {\nheight ~ normal(alpha, sigma); // likelihood\nalpha ~ normal(178, 20); // height prior\nsigma ~ uniform(0, 50);\n\n}\n\n\"\ncmdstanr::write_stan_file(\n  model_code,\n  \"linear-regression/stan-scripts\",\n  basename = \"simple_mod\"\n)\n\nmod1_dat <- just_adults |>\n  select(height, weight) |>\n  compose_data()\n\n\nmodels <- cmdstan_model(\n  stan_file = \"linear-regression/stan-scripts/simple_mod.stan\"\n)\n\nfitted_mod <- models$sample(\n  data = mod1_dat,\n  chains = 6\n)\n```\n:::\n\n\nThis will fit the model then lets extract the posterior draws \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfitted_mod$draws(format = \"df\") |>\n  summarise_draws()\n```\n:::\n\n\nThis roughly lets us get the output of the precis output. Lets see how well this replicates what I think should happen. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndraws_df <- fitted_mod$draws(format = \"df\")\n\nggplot(draws_df, aes(x = alpha)) +\n  stat_halfeye()\n```\n\n::: {.cell-output-display}\n![](linear-regression-in-stan_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nshe looks like swe are generally in the area of our prior. Now lets add height as a variable \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstan_mod2 <- \"\ndata {\nint <lower=1> n;\nvector[n] height;\nreal avg_weight;\nvector[n] weight;\n}\nparameters {\nreal alpha;\nreal <lower=0, upper = 50> sigma;\nreal <lower = 0> beta;\n}\nmodel {\nvector[n] mu;\nmu = alpha + beta * (weight - avg_weight);\nheight ~ normal(mu, sigma);\nbeta ~ lognormal(0, 1);\nalpha ~ normal(178, 20);\nsigma ~ uniform(0,50);\n}\n\n\n\"\n\nwrite_stan_file(\n  stan_mod2,\n  dir = \"linear-regression/stan-scripts/\",\n  basename = \"lognormal-mod.stan\"\n)\n\nlog_norm_mod <- cmdstan_model(\n  \"linear-regression/stan-scripts/lognormal-mod.stan\"\n)\n\n\nmodel_data2 <- just_adults |>\n  select(height, weight) |>\n  compose_data()\n\nmodel_data2$avg_weight <- mean(model_data2$weight)\n\n\nfitted_log_normal <- log_norm_mod$sample(data = model_data2)\n```\n:::\n\n\nCoool now we have the model. Generally we want some uncertainty around the parmeter so we can go ahead and fit some new data in the sampling code. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsampling_data <- tibble(n = c(10, 50, 150, 352))\n\nsampling_data <- sampling_data |>\n  mutate(\n    data = map(\n      .x = n,\n      ~ just_adults |>\n        slice(1:.x)\n    )\n  )\n\nprep_data <- sampling_data |>\n  mutate(\n    stan_data = map(\n      .x = data,\n      .f = ~ .x |> compose_data(avg_weight = mean(.x$weight))\n    )\n  )\n\n\ndraws_df <- prep_data |>\n  mutate(\n    samps = map(\n      .x = stan_data,\n      .f = ~ log_norm_mod$sample(\n        data = .x\n      )\n    )\n  )\n\nadd_draws <- draws_df |>\n  mutate(\n    draws = map(.x = samps, .f = ~ as_draws_df(.x) |> slice_sample(n = 20)),\n    xbar = map_dbl(.x = stan_data, .f = ~ .x[[\"avg_weight\"]]),\n    n = str_c(\"italic(n)==\", n) |>\n      factor(levels = str_c(\"italic(n)==\", c(10, 50, 150, 352)))\n  )\n\n\ndraws_plot <- add_draws |>\n  select(n, data, xbar) |>\n  unnest(data)\n\nlines_plot <- add_draws |>\n  select(n, xbar, draws) |>\n  unnest(draws)\n\n\nggplot() +\n  geom_point(data = draws_plot, aes(x = weight - xbar, y = height)) +\n  geom_abline(\n    data = lines_plot,\n    aes(slope = beta, intercept = alpha, group = .draw),\n    color = \"pink\"\n  ) +\n  facet_wrap(vars(n), labeller = label_parsed) +\n  scale_x_continuous(\n    \"weight\",\n    breaks = 3:6 * 10 - mean(just_adults$weight),\n    labels = 3:6 * 10\n  )\n```\n\n::: {.cell-output-display}\n![](linear-regression-in-stan_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nCool now we have a bunch of regression lines. What if we wanted to use some of the fun things in ggdist? Well lets get our draws data and then play around with it. If we wanted to plot the data at a variety of weights we could simply do  `height = alpha + beta * (weight - avg_weight)` \n\n\n\n## Contrast coding \n\n\n::: {.cell}\n\n```{.r .cell-code}\nadd_levels <- just_adults |>\n  mutate(sex = ifelse(male == 1, \"Male\", \"Female\"), sex = as.factor(sex))\n\nlevels_data <- compose_data(add_levels)\n\nlevels_data$avg_weight_female <- mean(add_levels$weight[\n  add_levels$sex == \"Female\"\n])\nlevels_data$avg_weight_male <- mean(add_levels$weight[add_levels$sex == \"Male\"])\nlevels_data$avg_weight <- mean(add_levels$weight)\n```\n:::\n\n\nWhat is interesting is that no matter what you do the compose data block will output a number for sex. This gives a lot of flexibility in how we specify priors. This will also change our approach to defining the model in stana \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat_model <- \"\n\ndata {\nint <lower = 1> n;\nint<lower = 1> n_sex;\narray[n] int sex;\nvector[n] height;\nreal avg_weight;\nvector[n] weight;\n}\nparameters {\nreal <lower=0> beta_weight;\nvector[n_sex] alpha;\nreal <lower = 0, upper = 50> sigma;\n\n}\nmodel {\nvector[n] mu;\n\nmu = alpha[sex] + beta_weight * (weight-avg_weight);\n\nheight ~ normal(mu, sigma);\n\nalpha[1] ~ normal(178,20);\n\nalpha[2] ~ normal(178, 20); // just assuming women are 5 cm shorter than men\n\nbeta_weight ~ lognormal(0, 1);\n\nsigma ~ uniform(0, 50);\n\n}\n\"\n\nwrite_stan_file(\n  cat_model,\n  dir = \"linear-regression/stan-scripts/\",\n  basename = \"categorical_model\"\n)\n\ncat_model <- cmdstan_model(\n  \"linear-regression/stan-scripts/categorical_model.stan\"\n)\n\nfitted_categorical_mod <- cat_model$sample(data = levels_data)\n```\n:::\n\n\n\nCool now lets get the draws and plot them\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrast_draws <- fitted_categorical_mod$draws(format = \"df\") |>\n  mutate(diff = `alpha[1]` - `alpha[2]`) |>\n  pivot_longer(\n    c(starts_with(\"alpha\"), diff),\n    names_to = \"sex\",\n    values_to = \"heights_by_sex\"\n  ) |>\n  mutate(\n    sex = case_when(\n      sex == \"alpha[1]\" ~ \"Male\",\n      sex == \"alpha[2]\" ~ \"Female\",\n      sex == \"diff\" ~ \"Posterior Contrast between Male and Female\"\n    )\n  )\n\n\nggplot(contrast_draws, aes(x = heights_by_sex)) +\n  stat_slab(normalize = \"panels\") +\n  stat_pointinterval() +\n  facet_wrap(vars(sex), scales = \"free_x\")\n```\n\n::: {.cell-output-display}\n![](linear-regression-in-stan_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\nCool. \n\n## Interaction Terms in Stan \n\n\nWe love an interaction in political science. My guess is it is actually really simple. He is using this rugged data package s\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"rugged\", package = \"rethinking\")\n\n\nclean_data <- rugged |>\n  filter(complete.cases(rgdppc_2000)) |>\n  mutate(\n    log_gdp = log(rgdppc_2000),\n    log_gdp_z = log_gdp / mean(log_gdp),\n    rugged_std = rugged / max(rugged),\n    nice_levels = ifelse(\n      cont_africa == 0,\n      \"Non-African Nation\",\n      \"African Nation\"\n    ),\n    cid = as.factor(cont_africa)\n  )\n\n\nstan_data <- clean_data |>\n  select(log_gdp, log_gdp_z, rugged_std, cid) |>\n  compose_data(\n    avg_rugged = mean(clean_data$rugged_std)\n  )\n```\n:::\n\n\nCool now that we have our data lets specify the model. The `.*` specifies an interaction for each level of \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nint_categorical_model <- \"\ndata {\n\nint <lower=1> n;\n\nint <lower=1> n_cid;\n\nreal avg_rugged;\n\narray[n] int cid;\n\nvector[n]  log_gdp_z;\n\nvector[n]  rugged_std;\n}\nparameters {\n\nvector[n_cid] alpha;\n\nvector[n_cid] beta_rugged;\n\nreal <lower=0> sigma;\n\n}\ntransformed parameters {\n\nvector[n] mu;\n\nmu = alpha[cid] + beta_rugged[cid] .* (rugged_std - avg_rugged);\n\n}\n\nmodel {\n\nlog_gdp_z ~ normal(mu, sigma);\n\nalpha ~ normal(1, 0.1);\n\nbeta_rugged ~ normal(0, 0.3);\n\nsigma ~ exponential(1);\n\n}\ngenerated quantities {\nvector[n] log_lik; // so we can calculate fit statistics\nfor(i in 1:n) log_lik[i] = normal_lpdf(log_gdp_z[i] | mu[i], sigma);\n\n}\n\n\"\n\nwrite_stan_file(\n  int_categorical_model,\n  dir = \"linear-regression/stan-scripts/\",\n  basename = \"categorical_int\"\n)\n\ncat_int_mod <- cmdstan_model(\n  \"linear-regression/stan-scripts/categorical_int.stan\"\n)\n\nfitted_int_mod <- cat_int_mod$sample(\n  data = stan_data\n)\n\nplot_levels <- fitted_int_mod$draws(format = \"df\") |>\n  as_draws_df() |>\n  select(.draw, `alpha[1]`:sigma) |>\n  expand_grid(\n    cid = 1:2,\n    rugged_std = seq(-0.1, to = 1.1, length.out = 25),\n    avg_rugged = mean(clean_data$rugged_std)\n  ) |>\n  mutate(\n    mu = case_when(\n      cid == \"1\" ~ `alpha[1]` + `beta_rugged[1]` * (rugged_std - avg_rugged),\n      cid == \"2\" ~ `alpha[2]` + `beta_rugged[2]` * (rugged_std - avg_rugged)\n    ),\n    nice_levels = ifelse(cid == 1, \"African Nation\", \"Non-African Nation\")\n  )\n\nggplot(plot_levels, aes(x = rugged_std, color = nice_levels)) +\n  stat_lineribbon(aes(y = mu, fill = nice_levels)) +\n  geom_point(data = clean_data, aes(y = log_gdp_z)) +\n  facet_wrap(vars(nice_levels)) +\n  xlim(0:1)\n```\n\n::: {.cell-output-display}\n![](linear-regression-in-stan_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n### Continous Interactions \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"tulips\", package = \"rethinking\")\n\nclean_tulips <- tulips |>\n  mutate(\n    blooms_std = blooms / max(blooms),\n    water_cent = water - mean(water),\n    shade_cent = shade - mean(shade)\n  )\n\nd_pred <- crossing(\n  water_cent = -1:1,\n  shade_cent = -1:1\n) |>\n  mutate(i = row_number())\n\ncont_int_data <-\n  clean_tulips |>\n  compose_data(\n    w_pred = pull(d_pred, water_cent),\n    s_pred = pull(d_pred, shade_cent),\n    n_pred = nrow(d_pred)\n  )\n```\n:::\n\n\n\nCool lets define the model \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncont_int_model <- \"\n\ndata {\nint <lower=0> n;\nint <lower=0> n_pred;\nvector[n] blooms_std;\nvector[n] shade_cent;\nvector[n] water_cent;\nvector[n_pred] s_pred;\nvector[n_pred] w_pred;\n\n}\nparameters {\nreal alpha;\nreal beta1;\nreal beta2;\nreal beta3;\nreal <lower=0> sigma;\n}\n\nmodel {\n\nblooms_std ~ normal(alpha + beta1 * water_cent + beta2 * shade_cent + beta3.* water_cent .* shade_cent, sigma);\n\nalpha ~ normal(0.5, 0.25);\n\n // long form\n//beta1 ~ normal(0, 0.25);\n\n//beta2 ~ normal(0, 0.25);\n\n//beta3 ~ normal(0, 0.25);\n\n[beta1, beta2, beta3] ~ normal(0, 0.25);\n\nsigma ~ exponential(1);\n\n\n\n}\n\ngenerated quantities {\n\nvector[n_pred] mu ;\nmu = alpha + beta1 * w_pred + beta2 * s_pred + beta3 .* w_pred .* s_pred;\n\n}\n\n\"\n\nwrite_stan_file(\n  cont_int_model,\n  \"linear-regression/stan-scripts\",\n  basename = \"cont-int\"\n)\n\nint_cont_model <- cmdstan_model(\"linear-regression/stan-scripts/cont-int.stan\")\n\nfitted_int_model <- int_cont_model$sample(\n  data = cont_int_data,\n  thin = 1,\n  iter_sampling = 2000,\n  iter_warmup = 1000\n)\n```\n:::\n\n\n\nCoolio we have the fitted model now its time to extract some things for plots. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndraws_from_int_model <- fitted_int_model$draws(format = \"df\")\n\nplotting_draws <-\n  spread_draws(draws_from_int_model, mu[i]) |>\n  left_join(d_pred, join_by(i)) |>\n  mutate(nice_labs = str_c(\"shade~(centered)==\", shade_cent)) |>\n  ungroup()\n\nggplot(plotting_draws, aes(x = water_cent, y = mu, group = .draw)) +\n  geom_point() +\n  geom_line(alpha = 0.5) +\n  facet_wrap(vars(nice_labs))\n```\n\n::: {.cell-output-display}\n![](linear-regression-in-stan_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nWhich gets us the plot from the book. Lets look at the diagnostics \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesplot::mcmc_trace(draws_from_int_model)\n```\n\n::: {.cell-output-display}\n![](linear-regression-in-stan_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}